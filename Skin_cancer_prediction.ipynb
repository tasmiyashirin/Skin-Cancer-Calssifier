{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLjqVLt0MAch"
   },
   "source": [
    "<h1> Importing libraries </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-umkKTNn8F2"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jo34K4ow86Z_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "qI2ONwYOPk2w",
    "outputId": "3f8a3405-9d2f-4f32-8483-8858b4d5b23c"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDg9JG-EBFdB",
    "outputId": "64e8e62e-ee12-4e68-8543-cb0b6ee33e9c"
   },
   "outputs": [],
   "source": [
    "cd Downloads/archive (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fc4S-johBKlt",
    "outputId": "93315c33-dbd6-42d6-b9c0-fb6a75361abc"
   },
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODAmYYGZMO5Y"
   },
   "source": [
    "<h1> Importing data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "gzg4JJtA87_r",
    "outputId": "f0805c92-a9d9-4f10-a8ca-a88a9f59bb8b"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_in_rgb(imagename):\n",
    "  return np.asarray(Image.open(imagename).convert(\"RGB\"))\n",
    "\n",
    "def Loading_Data_from(DIR, SIZE=224):\n",
    "    IMG = []\n",
    "    #tqdm used for showing in the format of progress loader\n",
    "    \n",
    "    for u in tqdm(os.listdir(DIR)):\n",
    "        filetype=os.listdir(DIR)[0][-4:]\n",
    "        Path_of_Image = os.path.join(DIR,u)\n",
    "        if filetype == \".jpg\":\n",
    "            image = read_in_rgb(Path_of_Image)\n",
    "           \n",
    "            image = cv2.resize(image, (SIZE,SIZE))\n",
    "           \n",
    "            IMG.append(np.array(image))\n",
    "    return IMG\n",
    "\n",
    "b_train = np.array(Loading_Data_from('data/train/benign'))\n",
    "m_train = np.array(Loading_Data_from('data/train/malignant'))\n",
    "b_test = np.array(Loading_Data_from('test/benign'))\n",
    "m_test = np.array(Loading_Data_from('test/malignant'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71EjIxYhMtno"
   },
   "source": [
    "<h1> Labelling dataset </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkOIPmP5Ks8f"
   },
   "outputs": [],
   "source": [
    "def return_labelled_data(x,y):\n",
    "  return np.concatenate((x, y), axis = 0)\n",
    "\n",
    "b_train_label = np.zeros(len(b_train))\n",
    "m_train_label = np.ones(len(m_train))\n",
    "b_test_label = np.zeros(len(b_test))\n",
    "m_test_label = np.ones(len(m_test))\n",
    "\n",
    "X_train = return_labelled_data(b_train, m_train)\n",
    "Y_train = return_labelled_data(b_train_label, m_train_label)\n",
    "X_test = return_labelled_data(b_test, m_test)\n",
    "Y_test = return_labelled_data(b_test_label, m_test_label)\n",
    "\n",
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train = X_train[s]\n",
    "Y_train = Y_train[s]\n",
    "\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "Y_test = Y_test[s]\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes= 2)\n",
    "Y_test = to_categorical(Y_test, num_classes= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bikiFzgBM0EP"
   },
   "source": [
    "<h3> Split test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0s4axYlyMxhe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X_train, Y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk2O8h8rQSaa"
   },
   "source": [
    "<h2> Bulding our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQf7fkDhOaoH"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def building_model(backbone, lr=1e-4):\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=lr),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "resnet = DenseNet201(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "model = building_model(resnet ,lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4cTfDIgQD3I"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSYdkaAlOgKN"
   },
   "outputs": [],
   "source": [
    "learn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n",
    "                                  verbose=1,factor=0.2, min_lr=1e-7)\n",
    "\n",
    "filepath=\"vgg16_1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n",
    "    epochs=5,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[learn_control, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8kskPSlBg0T"
   },
   "outputs": [],
   "source": [
    "with open('history.json', 'w') as f:\n",
    "    json.dump(str(history.history), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4qG_kBDCSCr"
   },
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxlJnuARD2UB"
   },
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdgSDnBzES2i"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urYSzODfEsF6"
   },
   "outputs": [],
   "source": [
    "tta_steps = 4\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(tta_steps)):\n",
    "    preds = model.predict_generator(train_generator.flow(X_test, batch_size=BATCH_SIZE, shuffle=False),\n",
    "                                    steps = len(X_test)/BATCH_SIZE)\n",
    "    \n",
    "    predictions.append(preds)\n",
    "    gc.collect()\n",
    "    \n",
    "Y_pred_tta = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGecfxViFBxR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "cm = confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))\n",
    "\n",
    "cm_plot_label =['benign', 'malignant']\n",
    "plot_confusion_matrix(cm, cm_plot_label, title ='Confusion Metrix for Skin Cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te_i0B9QFGjB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report( np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXVDl-sZHSHo"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "roc_log = roc_auc_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1))\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1))\n",
    "area_under_curve = auc(false_positive_rate, true_positive_rate)\n",
    "//roc- receiver operating characteristic curve(shows the performance of classification model)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tabtxLBhHaHv"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "prop_class=[]\n",
    "mis_class=[]\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if(np.argmax(Y_test[i])==np.argmax(Y_pred_tta[i])):\n",
    "        prop_class.append(i)\n",
    "    if(len(prop_class)==8):\n",
    "        break\n",
    "\n",
    "i=0\n",
    "for i in range(len(Y_test)):\n",
    "    if(not np.argmax(Y_test[i])==np.argmax(Y_pred_tta[i])):\n",
    "        mis_class.append(i)\n",
    "    if(len(mis_class)==8):\n",
    "        break\n",
    "\n",
    "# # Display first 8 images of benign\n",
    "w=60\n",
    "h=40\n",
    "fig=plt.figure(figsize=(18, 10))\n",
    "columns = 4\n",
    "rows = 2\n",
    "\n",
    "def Transfername(namecode):\n",
    "    if namecode==0:\n",
    "        return \"Benign\"\n",
    "    else:\n",
    "        return \"Malignant\"\n",
    "    \n",
    "for i in range(len(prop_class)):\n",
    "    ax = fig.add_subplot(rows, columns, i+1)\n",
    "    ax.set_title(\"Predicted result:\"+ Transfername(np.argmax(Y_pred_tta[prop_class[i]]))\n",
    "                       +\"\\n\"+\"Actual result: \"+ Transfername(np.argmax(Y_test[prop_class[i]])))\n",
    "    plt.imshow(X_test[prop_class[i]], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi6w1a6xKeUv"
   },
   "outputs": [],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AugJ5p4niapK"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CH_SW--WQd54"
   },
   "outputs": [],
   "source": [
    "cd drive/MyDrive/archive (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZ75Ix4ywz4Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2MrYtL9K0YQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zhyw4bGvahv"
   },
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4rcUE6UcKSa"
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = reconstructed_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "reconstructed_model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGM0TH7xdSkq"
   },
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BX0qgvlbdGt7"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zc0vI7gKvfHl"
   },
   "outputs": [],
   "source": [
    "img_path=\"test/benign/10.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BySZUN5WzMXP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab3_zVC1zQKl"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COgdLlK61FHz"
   },
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 224\n",
    "    img_array = cv2.imread(filepath)\n",
    "    img_array = cv2.cvtColor(img_array ,cv2.COLOR_BGR2RGB)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "prediction = loaded_model.predict([prepare(img_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoQyZR0u1Krv"
   },
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uD2pqf85H0y"
   },
   "outputs": [],
   "source": [
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8ElganfhZa4"
   },
   "outputs": [],
   "source": [
    "pkg_resources.get_distribution('tensorflow').version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xf0HFXzyhb_6"
   },
   "outputs": [],
   "source": [
    "pkg_resources.get_distribution('cv2').version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6BPC160h0O-"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2py2-oJh9aG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
